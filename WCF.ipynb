{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed6f24c-622a-43b8-997d-1614a117149f",
   "metadata": {},
   "source": [
    "# Wasserstein Collaborative Filtering for Item Cold-start Recommendation\n",
    "This is the python code for our 2020 UMAP paper \"Wasserstein Collaborative Filtering for Item Cold-start Recommendation\".<br>\n",
    "You have to run our code with Python and PyTorch. You could speed up training with your cuda devices, by setting options['gpu'] to 1. If you don't have any GPUs, setting options['gpu'] to 0. <br>\n",
    "Thank you for **citing** our paper:<br>\n",
    "*@inproceedings{meng2020wcf, title={Wasserstein Collaborative Filtering for Item Cold-start Recommendation}, author={Meng, Yitong and Yan, Xiao and Liu, Weiwen and Wu, Huanhuan and Cheng, James}, booktitle={Proceedings of the 28th ACM Conference on User Modeling, Adaptation and Personalization}, pages={318-322}, year={2020} } <br>*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b093e063-0417-43bc-ac0a-770a54b7016c",
   "metadata": {},
   "source": [
    "# Preparing data\n",
    "we assume there are $n$ users, $m$ warm items and $k$ cold-start items.<br>\n",
    "the train matrix is $n$ by $m$, M (the item distance matrix) is $m$ by $k$, test is $n$ by $k$.<br>\n",
    "The three returned matrices are numpy.array, and of course there are lots of 0 in them.<br>\n",
    "\n",
    "Here is a toy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d900fe59-83ea-43de-befd-fcb5386cabe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train = np.array([[3,0,0,0,0],[0,4,0,0,0],[0,0,0,5,0],[0,0,3,0,4]])\n",
    "M = np.array([[0.1,0.8],[0.2,0.9],[0.85,0.15],[0.9,0.1],[0.95,0.05]])\n",
    "test = np.array([[5,0],[4,0],[0,3],[0,5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0626fac4-2008-444c-80e3-abfd2f0a5361",
   "metadata": {},
   "source": [
    "We transpose train for the need of later training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d1e8fa-a8b7-40bc-b964-70dfb0337a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d78972-8e88-4ff7-8a60-58f16ab35edd",
   "metadata": {},
   "source": [
    "We normalize the rating values of each user, and convert nan to zero if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3475a643-49fe-4482-8f23-b06ed44244b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train/sum(train) # sum() is summing each column of train\n",
    "train=np.nan_to_num(train) # convert nan to zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1508a892-92c5-46c6-90ef-5608a120f0cd",
   "metadata": {},
   "source": [
    "We convert all the data to PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a20ef8-ab0d-4495-8fac-b370bfea404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tc\n",
    "\n",
    "Tensor=lambda M:tc.DoubleTensor(M)\n",
    "train=Tensor(train)\n",
    "M=Tensor(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b84270-7bd6-4d7c-8e74-07e80ffb86fd",
   "metadata": {},
   "source": [
    "## Training WCF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be934349-cf1f-4ec4-b5f2-d411df0367f5",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "256d58a1-227f-451b-99f9-29fae7c2af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tcwasserstein_DL as wd\n",
    "import tcutil as ut\n",
    "import  torch as tc\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb4578-7dbd-434d-b692-0044fdf14dcf",
   "metadata": {},
   "source": [
    "Initialize hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43e6b1e3-17dc-4007-bffa-ee3739af39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "options={}\n",
    "options['stop']=1e-5 # if the change of the loss function is smaller than this ratio, stop training.\n",
    "options['t0']=10 # this is a parameter userd for backtrack in linear_projected_gradient_descent, which is a technique used in the optimization process.\n",
    "options['verbose']=1 # set to 1 if you want to print verbal information.\n",
    "options['D_step_stop']=1e-3 # this is a parameter userd for linear_projected_gradient_descent, which is a technique used in the optimization process. You can simply use this fixed value here.\n",
    "options['lambda_step_stop']=1e-2 # this is a parameter userd for linear_projected_gradient_descent, which is a technique used in the optimization process. \n",
    "options['alpha']=0.5 # this is a parameter userd for backtrack in linear_projected_gradient_descent, which is a technique used in the optimization process.\n",
    "options['beta']=0.8 # this is a parameter userd for backtrack in linear_projected_gradient_descent, which is a technique used in the optimization process.\n",
    "options['gpu']=0 # 0 is using cpu, 1 is using gpu.\n",
    "k = 2 # the latent dimension of the \"[user] by [cold-start item]\" marix.\n",
    "gamma=1/50 # gamma correspond to eq (4) of our paper. It controls the importance of the Entropy regularization term.\n",
    "rho1=0 # rho1 and roh2 should be set to 0. rho1 and roh2 are parameters correspond to eq (9) in reference [27], which are used for nonnegtive matrix factorization. In our paper, we don't do nonnegtive matrix factorization and thus these parameters should be set to 0. While, I did implement the nonnegtive matrix factorization part in my code and you can use it by setting rho1 and roh2 to non-zero values for other research purposes. \n",
    "rho2=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cad1c4-621f-4030-8ad9-7344225c6230",
   "metadata": {},
   "source": [
    "Transfer parameters to pytorch Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ba2c4d-656f-44a6-8416-ba135c07dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor=lambda M:tc.DoubleTensor(M)\n",
    "\n",
    "for key, value in options.items():\n",
    "    options[key] = Tensor([value])\n",
    "\n",
    "gamma= Tensor([gamma])\n",
    "rho1 = Tensor([rho1])\n",
    "rho2 = Tensor([rho2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695f30dc-011e-4575-b20e-f892ada5777c",
   "metadata": {},
   "source": [
    "Initialize model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54fbee74-3586-4f35-9457-2c6621aea37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeD=(M.shape[1],k)\n",
    "D, HD, Hlambda=ut.initialValue(train,sizeD,options['gpu'],Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d09490-ce03-417b-a7b5-8f19d8b65bc8",
   "metadata": {},
   "source": [
    "You are encouraged to use GPU, by switching options['gpu'] on (to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc49122d-d17e-4722-b06a-10c2f1837888",
   "metadata": {},
   "outputs": [],
   "source": [
    "if options['gpu']:\n",
    "    data = data.cuda()\n",
    "    M = M.cuda()\n",
    "    for key, value in options.items():\n",
    "        options[key]=value.cuda()\n",
    "    gamma= gamma.cuda()\n",
    "    rho1 = rho1.cuda()\n",
    "    rho2 = rho2.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9866ac3-2c2e-4800-a687-d7024178c599",
   "metadata": {},
   "source": [
    "Training WCF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1f1eb17-c78d-474d-8471-03232f977874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 2 ; gamma: [0.02] ; rhoL: [0.] ; rhoD: [0.] ; lambda_step_stop: [0.01] ; D_step_stop:  [0.001] ; stop: [1.e-05]\n",
      "1\n",
      "Optimize with respect to lambda\n",
      "Optimize with respect to D\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "D, lambdA, objectives=wd.wasserstein_DL(train,k,M,gamma,rho1,rho2,D, HD, Hlambda, options,Tensor)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505ff66-386d-49c8-a18c-9ef811946616",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9636849-2862-4f2b-86df-38a44a1fe71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAP: 1.0 NDCG: 1.0 recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "pred = D @ lambdA\n",
    "pred = pred.cpu().data.numpy()\n",
    "# print(pred.T)\n",
    "import evaluate as ev\n",
    "performance = ev.eval2(pred.T, test)\n",
    "print('\\tMAP:',performance[0],'NDCG:',performance[1],'recall:',performance[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5977b3-3d4d-4218-a686-77cbee33a7ca",
   "metadata": {},
   "source": [
    "## Miscellaneous\n",
    "Hope our work can help you in your research:) <br>\n",
    "If you have any questions regarding our work, please contact Yitong Meng via mengyitongge@163.com ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f712b5a6-6055-400f-99d3-820dac8e3722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
